{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1772238e",
   "metadata": {},
   "source": [
    "# Essay Topic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2481180",
   "metadata": {},
   "source": [
    "In this notebook, we use the package NLTK (natural lanuage toolkit) to do a topic analysis of the dataset of essays. We create a ChatGPT prompt and essay from these topics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e77dfc",
   "metadata": {},
   "source": [
    "Lets import each text file from our data set as a string into a text_list using the os module, and then read off the first entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10250e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'data/train'\n",
    "\n",
    "file_list = [file for file in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, file))]\n",
    "file_list.sort() \n",
    "# os.listdir() returns the file list in random(ish) order. Sort to standardize.\n",
    "\n",
    "text_list =[]\n",
    "\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        text_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3425f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some people belive that the so called \"face\" on mars was created by life on mars. This is not the case. The face on Mars is a naturally occuring land form called a mesa. It was not created by aliens, and there is no consiracy to hide alien lifeforms on mars. There is no evidence that NASA has found that even suggests that this face was created by aliens.\\n\\nA mesa is a naturally occuring rock formation, that is found on Mars and Earth. This \"face\" on mars only looks like a face because humans tend to see faces wherever we look, humans are obviously extremely social, which is why our brain is designed to recognize faces.\\n\\nMany conspiracy theorists believe that NASA is hiding life on Mars from the rest of the world. These people would be very wrong. If NASA found life on Mars, then they would get millions of people\\'s attention. NASA\\'s budget would increase drasticly, which means that their workers would get paid more. There is no good reason that NASA would hide life on Mars from the rest of the world.\\n\\nSo, NASA is not hiding life on Mars from us, and they are not trying to trick us into thinking that the \"face\" on mars is just a mesa, because it actually is. NASA hiding life would be illogical, because if they found life on Mars, they would make a lot of money, and we all know that the people at NASA aren\\'t illogical people.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd740027",
   "metadata": {},
   "source": [
    "Next, we form a list of the tokenized texts composed of the lowercase words each contains. The lowercasing is preprocessing to be used when we investigate the topic of the text. Then we remove all non-alphabetic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e711a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "words_in_text = [word_tokenize(text.lower()) for text in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86cd13be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some',\n",
       " 'people',\n",
       " 'belive',\n",
       " 'that',\n",
       " 'the',\n",
       " 'so',\n",
       " 'called',\n",
       " '``',\n",
       " 'face',\n",
       " \"''\",\n",
       " 'on',\n",
       " 'mars',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " '.',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'the',\n",
       " 'case',\n",
       " '.',\n",
       " 'the',\n",
       " 'face',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'is',\n",
       " 'a',\n",
       " 'naturally',\n",
       " 'occuring',\n",
       " 'land',\n",
       " 'form',\n",
       " 'called',\n",
       " 'a',\n",
       " 'mesa',\n",
       " '.',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'created',\n",
       " 'by',\n",
       " 'aliens',\n",
       " ',',\n",
       " 'and',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'consiracy',\n",
       " 'to',\n",
       " 'hide',\n",
       " 'alien',\n",
       " 'lifeforms',\n",
       " 'on',\n",
       " 'mars',\n",
       " '.',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'evidence',\n",
       " 'that',\n",
       " 'nasa',\n",
       " 'has',\n",
       " 'found',\n",
       " 'that',\n",
       " 'even',\n",
       " 'suggests',\n",
       " 'that',\n",
       " 'this',\n",
       " 'face',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'aliens',\n",
       " '.',\n",
       " 'a',\n",
       " 'mesa',\n",
       " 'is',\n",
       " 'a',\n",
       " 'naturally',\n",
       " 'occuring',\n",
       " 'rock',\n",
       " 'formation',\n",
       " ',',\n",
       " 'that',\n",
       " 'is',\n",
       " 'found',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'and',\n",
       " 'earth',\n",
       " '.',\n",
       " 'this',\n",
       " '``',\n",
       " 'face',\n",
       " \"''\",\n",
       " 'on',\n",
       " 'mars',\n",
       " 'only',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'a',\n",
       " 'face',\n",
       " 'because',\n",
       " 'humans',\n",
       " 'tend',\n",
       " 'to',\n",
       " 'see',\n",
       " 'faces',\n",
       " 'wherever',\n",
       " 'we',\n",
       " 'look',\n",
       " ',',\n",
       " 'humans',\n",
       " 'are',\n",
       " 'obviously',\n",
       " 'extremely',\n",
       " 'social',\n",
       " ',',\n",
       " 'which',\n",
       " 'is',\n",
       " 'why',\n",
       " 'our',\n",
       " 'brain',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'faces',\n",
       " '.',\n",
       " 'many',\n",
       " 'conspiracy',\n",
       " 'theorists',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'nasa',\n",
       " 'is',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'from',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'these',\n",
       " 'people',\n",
       " 'would',\n",
       " 'be',\n",
       " 'very',\n",
       " 'wrong',\n",
       " '.',\n",
       " 'if',\n",
       " 'nasa',\n",
       " 'found',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " ',',\n",
       " 'then',\n",
       " 'they',\n",
       " 'would',\n",
       " 'get',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'people',\n",
       " \"'s\",\n",
       " 'attention',\n",
       " '.',\n",
       " 'nasa',\n",
       " \"'s\",\n",
       " 'budget',\n",
       " 'would',\n",
       " 'increase',\n",
       " 'drasticly',\n",
       " ',',\n",
       " 'which',\n",
       " 'means',\n",
       " 'that',\n",
       " 'their',\n",
       " 'workers',\n",
       " 'would',\n",
       " 'get',\n",
       " 'paid',\n",
       " 'more',\n",
       " '.',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'good',\n",
       " 'reason',\n",
       " 'that',\n",
       " 'nasa',\n",
       " 'would',\n",
       " 'hide',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'from',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'so',\n",
       " ',',\n",
       " 'nasa',\n",
       " 'is',\n",
       " 'not',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'from',\n",
       " 'us',\n",
       " ',',\n",
       " 'and',\n",
       " 'they',\n",
       " 'are',\n",
       " 'not',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'trick',\n",
       " 'us',\n",
       " 'into',\n",
       " 'thinking',\n",
       " 'that',\n",
       " 'the',\n",
       " '``',\n",
       " 'face',\n",
       " \"''\",\n",
       " 'on',\n",
       " 'mars',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'mesa',\n",
       " ',',\n",
       " 'because',\n",
       " 'it',\n",
       " 'actually',\n",
       " 'is',\n",
       " '.',\n",
       " 'nasa',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'would',\n",
       " 'be',\n",
       " 'illogical',\n",
       " ',',\n",
       " 'because',\n",
       " 'if',\n",
       " 'they',\n",
       " 'found',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " ',',\n",
       " 'they',\n",
       " 'would',\n",
       " 'make',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'money',\n",
       " ',',\n",
       " 'and',\n",
       " 'we',\n",
       " 'all',\n",
       " 'know',\n",
       " 'that',\n",
       " 'the',\n",
       " 'people',\n",
       " 'at',\n",
       " 'nasa',\n",
       " 'are',\n",
       " \"n't\",\n",
       " 'illogical',\n",
       " 'people',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2be0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_text_alp = [ [word for word in text if word.isalpha()]\n",
    "                      for text in words_in_text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92952d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['some',\n",
       " 'people',\n",
       " 'belive',\n",
       " 'that',\n",
       " 'the',\n",
       " 'so',\n",
       " 'called',\n",
       " 'face',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'the',\n",
       " 'case',\n",
       " 'the',\n",
       " 'face',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'is',\n",
       " 'a',\n",
       " 'naturally',\n",
       " 'occuring',\n",
       " 'land',\n",
       " 'form',\n",
       " 'called',\n",
       " 'a',\n",
       " 'mesa',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'created',\n",
       " 'by',\n",
       " 'aliens',\n",
       " 'and',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'consiracy',\n",
       " 'to',\n",
       " 'hide',\n",
       " 'alien',\n",
       " 'lifeforms',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'evidence',\n",
       " 'that',\n",
       " 'nasa',\n",
       " 'has',\n",
       " 'found',\n",
       " 'that',\n",
       " 'even',\n",
       " 'suggests',\n",
       " 'that',\n",
       " 'this',\n",
       " 'face',\n",
       " 'was',\n",
       " 'created',\n",
       " 'by',\n",
       " 'aliens',\n",
       " 'a',\n",
       " 'mesa',\n",
       " 'is',\n",
       " 'a',\n",
       " 'naturally',\n",
       " 'occuring',\n",
       " 'rock',\n",
       " 'formation',\n",
       " 'that',\n",
       " 'is',\n",
       " 'found',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'and',\n",
       " 'earth',\n",
       " 'this',\n",
       " 'face',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'only',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'a',\n",
       " 'face',\n",
       " 'because',\n",
       " 'humans',\n",
       " 'tend',\n",
       " 'to',\n",
       " 'see',\n",
       " 'faces',\n",
       " 'wherever',\n",
       " 'we',\n",
       " 'look',\n",
       " 'humans',\n",
       " 'are',\n",
       " 'obviously',\n",
       " 'extremely',\n",
       " 'social',\n",
       " 'which',\n",
       " 'is',\n",
       " 'why',\n",
       " 'our',\n",
       " 'brain',\n",
       " 'is',\n",
       " 'designed',\n",
       " 'to',\n",
       " 'recognize',\n",
       " 'faces',\n",
       " 'many',\n",
       " 'conspiracy',\n",
       " 'theorists',\n",
       " 'believe',\n",
       " 'that',\n",
       " 'nasa',\n",
       " 'is',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'from',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'these',\n",
       " 'people',\n",
       " 'would',\n",
       " 'be',\n",
       " 'very',\n",
       " 'wrong',\n",
       " 'if',\n",
       " 'nasa',\n",
       " 'found',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'then',\n",
       " 'they',\n",
       " 'would',\n",
       " 'get',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'people',\n",
       " 'attention',\n",
       " 'nasa',\n",
       " 'budget',\n",
       " 'would',\n",
       " 'increase',\n",
       " 'drasticly',\n",
       " 'which',\n",
       " 'means',\n",
       " 'that',\n",
       " 'their',\n",
       " 'workers',\n",
       " 'would',\n",
       " 'get',\n",
       " 'paid',\n",
       " 'more',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'good',\n",
       " 'reason',\n",
       " 'that',\n",
       " 'nasa',\n",
       " 'would',\n",
       " 'hide',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'from',\n",
       " 'the',\n",
       " 'rest',\n",
       " 'of',\n",
       " 'the',\n",
       " 'world',\n",
       " 'so',\n",
       " 'nasa',\n",
       " 'is',\n",
       " 'not',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'from',\n",
       " 'us',\n",
       " 'and',\n",
       " 'they',\n",
       " 'are',\n",
       " 'not',\n",
       " 'trying',\n",
       " 'to',\n",
       " 'trick',\n",
       " 'us',\n",
       " 'into',\n",
       " 'thinking',\n",
       " 'that',\n",
       " 'the',\n",
       " 'face',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'is',\n",
       " 'just',\n",
       " 'a',\n",
       " 'mesa',\n",
       " 'because',\n",
       " 'it',\n",
       " 'actually',\n",
       " 'is',\n",
       " 'nasa',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'would',\n",
       " 'be',\n",
       " 'illogical',\n",
       " 'because',\n",
       " 'if',\n",
       " 'they',\n",
       " 'found',\n",
       " 'life',\n",
       " 'on',\n",
       " 'mars',\n",
       " 'they',\n",
       " 'would',\n",
       " 'make',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'money',\n",
       " 'and',\n",
       " 'we',\n",
       " 'all',\n",
       " 'know',\n",
       " 'that',\n",
       " 'the',\n",
       " 'people',\n",
       " 'at',\n",
       " 'nasa',\n",
       " 'are',\n",
       " 'illogical',\n",
       " 'people']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_text_alp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f284d08",
   "metadata": {},
   "source": [
    "Calculate the mean and median for the entire list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c215c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average word count without punctuation: 417.6122867769655\n",
      "\n",
      "Median word count without punctuation: 380.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "word_lengths = [len(w) for w in words_in_text_alp]\n",
    "\n",
    "average_word_count = np.mean(word_lengths)\n",
    "median_word_count = np.median(word_lengths)\n",
    "\n",
    "print(f\"Average word count without punctuation: {average_word_count}\")\n",
    "print()\n",
    "print(f\"Median word count without punctuation: {median_word_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcc8cb",
   "metadata": {},
   "source": [
    "Topic Identification -- find key words to distinguish context. We first naively count the most common words in the first semi-processed list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "329cf3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 13),\n",
       " ('on', 12),\n",
       " ('mars', 12),\n",
       " ('that', 10),\n",
       " ('the', 9),\n",
       " ('nasa', 8),\n",
       " ('life', 7),\n",
       " ('a', 7),\n",
       " ('would', 7),\n",
       " ('face', 6)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(words_in_text_alp[0]).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3547b",
   "metadata": {},
   "source": [
    "We produce a simple processing/cleaning of the data in order to get rid of these common occurances as they clearly do not contribute to the context of the paragraph. We first download the wordnet package, even though we use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "450adedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/derekkielty/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30228986",
   "metadata": {},
   "source": [
    "In order to preprocess, lets first remove stop words to clarify context by removing redundant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69fb522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "no_stops = [ [word for word in text_alp if word not in stop_words]\n",
    "            for text_alp in words_in_text_alp ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfb0a9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['people',\n",
       " 'belive',\n",
       " 'called',\n",
       " 'face',\n",
       " 'mars',\n",
       " 'created',\n",
       " 'life',\n",
       " 'mars',\n",
       " 'case',\n",
       " 'face',\n",
       " 'mars',\n",
       " 'naturally',\n",
       " 'occuring',\n",
       " 'land',\n",
       " 'form',\n",
       " 'called',\n",
       " 'mesa',\n",
       " 'created',\n",
       " 'aliens',\n",
       " 'consiracy',\n",
       " 'hide',\n",
       " 'alien',\n",
       " 'lifeforms',\n",
       " 'mars',\n",
       " 'evidence',\n",
       " 'nasa',\n",
       " 'found',\n",
       " 'even',\n",
       " 'suggests',\n",
       " 'face',\n",
       " 'created',\n",
       " 'aliens',\n",
       " 'mesa',\n",
       " 'naturally',\n",
       " 'occuring',\n",
       " 'rock',\n",
       " 'formation',\n",
       " 'found',\n",
       " 'mars',\n",
       " 'earth',\n",
       " 'face',\n",
       " 'mars',\n",
       " 'looks',\n",
       " 'like',\n",
       " 'face',\n",
       " 'humans',\n",
       " 'tend',\n",
       " 'see',\n",
       " 'faces',\n",
       " 'wherever',\n",
       " 'look',\n",
       " 'humans',\n",
       " 'obviously',\n",
       " 'extremely',\n",
       " 'social',\n",
       " 'brain',\n",
       " 'designed',\n",
       " 'recognize',\n",
       " 'faces',\n",
       " 'many',\n",
       " 'conspiracy',\n",
       " 'theorists',\n",
       " 'believe',\n",
       " 'nasa',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'mars',\n",
       " 'rest',\n",
       " 'world',\n",
       " 'people',\n",
       " 'would',\n",
       " 'wrong',\n",
       " 'nasa',\n",
       " 'found',\n",
       " 'life',\n",
       " 'mars',\n",
       " 'would',\n",
       " 'get',\n",
       " 'millions',\n",
       " 'people',\n",
       " 'attention',\n",
       " 'nasa',\n",
       " 'budget',\n",
       " 'would',\n",
       " 'increase',\n",
       " 'drasticly',\n",
       " 'means',\n",
       " 'workers',\n",
       " 'would',\n",
       " 'get',\n",
       " 'paid',\n",
       " 'good',\n",
       " 'reason',\n",
       " 'nasa',\n",
       " 'would',\n",
       " 'hide',\n",
       " 'life',\n",
       " 'mars',\n",
       " 'rest',\n",
       " 'world',\n",
       " 'nasa',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'mars',\n",
       " 'us',\n",
       " 'trying',\n",
       " 'trick',\n",
       " 'us',\n",
       " 'thinking',\n",
       " 'face',\n",
       " 'mars',\n",
       " 'mesa',\n",
       " 'actually',\n",
       " 'nasa',\n",
       " 'hiding',\n",
       " 'life',\n",
       " 'would',\n",
       " 'illogical',\n",
       " 'found',\n",
       " 'life',\n",
       " 'mars',\n",
       " 'would',\n",
       " 'make',\n",
       " 'lot',\n",
       " 'money',\n",
       " 'know',\n",
       " 'people',\n",
       " 'nasa',\n",
       " 'illogical',\n",
       " 'people']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_stops[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29667343",
   "metadata": {},
   "source": [
    "Lastly, we lemmatize our no_stops list of lists, we downloaded the wordnet previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12d78ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Instatiate \n",
    "word_net = WordNetLemmatizer()\n",
    " \n",
    "lemmatized = [ [(word_net.lemmatize(t)) for t in no_stop ]\n",
    "              for no_stop in no_stops ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9de74",
   "metadata": {},
   "source": [
    "Next we can count the common words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4489c34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mar', 12),\n",
       " ('face', 8),\n",
       " ('nasa', 8),\n",
       " ('life', 7),\n",
       " ('would', 7),\n",
       " ('people', 5),\n",
       " ('found', 4),\n",
       " ('created', 3),\n",
       " ('mesa', 3),\n",
       " ('alien', 3)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_topic_freq = Counter(lemmatized[0]).most_common(10)\n",
    "mars_topic_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e4d8f",
   "metadata": {},
   "source": [
    "Next, I will feed the above key words to ChatGPT: \n",
    "\n",
    "Input : \"Write an essay as though it is written by 6-12 grader that is no more than 420 words based on the keywords : mars, face, nasa, would, life, people, found, created, mesa, alien\" \n",
    "\n",
    "( Not sure if this isn't specific enough, or even the best way to prompt the question )\n",
    "\n",
    "Output : \"Title: My Amazing Adventure to Mars: The Search for Aliens and the Mysterious Face\n",
    "\n",
    "Hey there, fellow explorers! Let me tell you about this incredible journey to Mars. Imagine a planet with red deserts and rocky landscapes, where scientists from NASA are sending cool rovers to find signs of life. And guess what? There's this mysterious mesa that people used to think looked like a giant face!\n",
    "\n",
    "Back in 1976, NASA's Viking 1 spacecraft sent back a picture of a mesa on Mars that everyone thought was a face. It was like something out of a sci-fi movie! But later, when newer pictures came in, the face turned out to be just a funny-shaped hill. Still, the idea of finding a face on another planet got everyone super excited.\n",
    "\n",
    "Now, why are we so obsessed with Mars? Well, NASA believes there might be tiny living things, like microbes, hiding under the surface or in old Martian lakes. How cool would that be? It's like playing hide and seek with aliens on a whole other planet!\n",
    "\n",
    "The rovers NASA created, like Curiosity, are like our robotic buddies exploring Mars for us. These machines are super smart and have all sorts of tools to dig, sniff, and take awesome pictures. They're like our interplanetary detectives, searching for clues that could tell us if Mars ever had or still has any form of life.\n",
    "\n",
    "Just think about it – if those rovers found even the tiniest hint of life on Mars, it would be mind-blowing! It would mean that we're not alone in this vast universe. It would be like discovering a whole new neighborhood of alien neighbors.\n",
    "\n",
    "But getting to Mars and sending these cool rovers isn't easy. It takes a lot of brainpower from scientists and engineers who design and build these amazing space machines. They're like the superheroes of space exploration, using their smarts to unlock the secrets of the universe.\n",
    "\n",
    "The idea of aliens has always been a big mystery that sparks our imagination. We wonder what they might look like and if they're friendly or not. Finding life on Mars would be like making friends with aliens, and that's just awesome to think about!\n",
    "\n",
    "So, here's to the brave people at NASA and their rovers, exploring Mars and searching for signs of life. Who knows what they might discover next? Maybe they'll find something even cooler than a face – maybe they'll find our future Martian pals! It's like the best space adventure ever, and we're all a part of it, dreaming big and reaching for the stars.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f978173",
   "metadata": {},
   "source": [
    "### Topic Analysis of ChatGPT Mars Essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d4ffa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My Amazing Adventure to Mars: The Search for Aliens and the Mysterious Face\\nHey there, fellow explorers! Let me tell you about this incredible journey to Mars. Imagine a planet with red deserts and rocky landscapes, where scientists from NASA are sending cool rovers to find signs of life. And guess what? There's this mysterious mesa that people used to think looked like a giant face!\\nBack in 1976, NASA's Viking 1 spacecraft sent back a picture of a mesa on Mars that everyone thought was a face. It was like something out of a sci-fi movie! But later, when newer pictures came in, the face turned out to be just a funny-shaped hill. Still, the idea of finding a face on another planet got everyone super excited.\\nNow, why are we so obsessed with Mars? Well, NASA believes there might be tiny living things, like microbes, hiding under the surface or in old Martian lakes. How cool would that be? It's like playing hide and seek with aliens on a whole other planet!\\nThe rovers NASA created, like Curiosity, are like our robotic buddies exploring Mars for us. These machines are super smart and have all sorts of tools to dig, sniff, and take awesome pictures. They're like our interplanetary detectives, searching for clues that could tell us if Mars ever had or still has any form of life.\\nJust think about it – if those rovers found even the tiniest hint of life on Mars, it would be mind-blowing! It would mean that we're not alone in this vast universe. It would be like discovering a whole new neighborhood of alien neighbors.\\nBut getting to Mars and sending these cool rovers isn't easy. It takes a lot of brainpower from scientists and engineers who design and build these amazing space machines. They're like the superheroes of space exploration, using their smarts to unlock the secrets of the universe.\\nThe idea of aliens has always been a big mystery that sparks our imagination. We wonder what they might look like and if they're friendly or not. Finding life on Mars would be like making friends with aliens, and that's just awesome to think about!\\nSo, here's to the brave people at NASA and their rovers, exploring Mars and searching for signs of life. Who knows what they might discover next? Maybe they'll find something even cooler than a face – maybe they'll find our future Martian pals! It's like the best space adventure ever, and we're all a part of it, dreaming big and reaching for the stars.\\n\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_GPT_path = 'mars_GPT_essay.txt'\n",
    "with open(mars_GPT_path, 'r', encoding='utf-8') as file:\n",
    "        mars_GPT_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d0a675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same analysis as above on the GPT mars essay\n",
    "#Should just write a function to do this\n",
    "\n",
    "mars_GPT_words = word_tokenize(mars_GPT_text.lower())\n",
    "mars_GPT_alp = [word for word in mars_GPT_words if word.isalpha()]\n",
    "mars_GPT_no_stop = [word for word in mars_GPT_alp if word not in stop_words]\n",
    "mars_GPT_lem = [(word_net.lemmatize(t)) for t in mars_GPT_no_stop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4f5d0c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('like', 12),\n",
       " ('mar', 10),\n",
       " ('face', 6),\n",
       " ('alien', 5),\n",
       " ('nasa', 5),\n",
       " ('rover', 5),\n",
       " ('life', 5),\n",
       " ('would', 5),\n",
       " ('planet', 3),\n",
       " ('cool', 3)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mars_GPT_topic_freq = Counter(mars_GPT_lem).most_common(10)\n",
    "mars_GPT_topic_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "49716f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_topics = [topic[0] for topic in mars_topic_freq]\n",
    "mars_GPT_topics = [topic[0] for topic in mars_GPT_topic_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ee3d33b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mar', 'face', 'nasa', 'life', 'would', 'people', 'found', 'created', 'mesa', 'alien']\n",
      "['like', 'mar', 'face', 'alien', 'nasa', 'rover', 'life', 'would', 'planet', 'cool']\n",
      "{'mar', 'face', 'would', 'alien', 'life', 'nasa'}\n"
     ]
    }
   ],
   "source": [
    "print(mars_topics)\n",
    "print(mars_GPT_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c3d09f",
   "metadata": {},
   "source": [
    "The collection of \"topics\" have 6 elements in common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02ee5299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mar', 'face', 'would', 'alien', 'life', 'nasa'}\n"
     ]
    }
   ],
   "source": [
    "print(set(mars_topics).intersection(mars_GPT_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf39dc3e",
   "metadata": {},
   "source": [
    "### Topic Analysis of ChatGPT Driving Essay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424aa29",
   "metadata": {},
   "source": [
    "As a second go through, we will also look at the second entry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "37f69fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_topic_freq = Counter(lemmatized[1]).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7e2a5c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('car', 23),\n",
       " ('driverless', 7),\n",
       " ('could', 6),\n",
       " ('thing', 6),\n",
       " ('driver', 6),\n",
       " ('call', 5),\n",
       " ('one', 5),\n",
       " ('article', 5),\n",
       " ('wrong', 5),\n",
       " ('developement', 4)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_topic_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e61b1",
   "metadata": {},
   "source": [
    "Input : \"Write an essay as though it is written by 6-12 grader that is no more than 420 words based on the keywords : car, driverless, could, thing, driver, call, one, article, wrong, development\"\n",
    "\n",
    "Output: \"Title: The Coolness of Driverless Cars: A Rollercoaster Ride into the Future\n",
    "\n",
    "Have you ever imagined a world where cars drive themselves? It might sound like something from a futuristic movie, but guess what? Driverless cars could be a real thing, and they're cooler than you might think!\n",
    "\n",
    "First off, let's talk about what a driverless car is. It's like having a super-smart robot buddy take you wherever you want to go. You just hop in, tell the car where you want to be, and boom, you're off! No need for a grown-up driver – you're in charge, and it's like having your own personal chauffeur.\n",
    "\n",
    "Now, why are people so excited about driverless cars? Well, for one, they could make our roads safer. You know how sometimes drivers can get distracted or tired? With driverless cars, there's no need to worry about that. These cars don't get sleepy or check their phones; they're like the superheroes of the road, always alert and ready to keep us safe.\n",
    "\n",
    "Imagine being able to call one of these cool cars whenever you need to go somewhere. No more waiting for your parents to drive you around – you're the boss of your own transportation! It's like having your own magic carpet, but instead of flying, it cruises on the roads, taking you to your favorite places.\n",
    "\n",
    "Some people in an article I read said that driverless cars might be a bad thing. They're worried about the development of this new technology and think it could go wrong. But here's the thing – scientists and really smart people are working hard to make sure these cars are super safe. It's like having a bunch of wizards making sure our magical ride is the best and safest it can be.\n",
    "\n",
    "And get this – driverless cars could be good for the planet too. They might be able to drive more smoothly, using less fuel and creating fewer yucky emissions. So not only are they like your personal chauffeur, but they're also helping to take care of our Earth. How awesome is that?\n",
    "\n",
    "Sure, there might be a few bumps in the road as we figure things out, but that's how it is with anything new. Remember when your parents first gave you the keys to your bike, and you wobbled a bit before becoming a biking pro? It's the same idea with driverless cars – we're learning and getting better every day.\n",
    "\n",
    "So, next time someone says driverless cars are a bad thing, just remember the coolness they bring – safety, independence, and a greener planet. It's like stepping into the future, and who wouldn't want to be a part of that awesome adventure? Buckle up, fellow adventurers – the driverless car rollercoaster ride is just beginning!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0bbf2e",
   "metadata": {},
   "source": [
    "Remarks : There are a good amount of question marks and apostrophies, this could be how the question is posed.\n",
    "          Also the text really appears to read rather colloquially it seems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "73cdda0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_GPT_path = 'driving_GPT_essay.txt'\n",
    "with open(driving_GPT_path, 'r', encoding='utf-8') as file:\n",
    "        driving_GPT_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fe8eab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_GPT_words = word_tokenize(driving_GPT_text.lower())\n",
    "driving_GPT_alp = [word for word in driving_GPT_words if word.isalpha()]\n",
    "driving_GPT_no_stop = [word for word in driving_GPT_alp if word not in stop_words]\n",
    "driving_GPT_lem = [(word_net.lemmatize(t)) for t in driving_GPT_no_stop ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e571a3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('car', 26),\n",
       " ('driverless', 16),\n",
       " ('like', 14),\n",
       " ('might', 10),\n",
       " ('could', 8),\n",
       " ('thing', 8),\n",
       " ('road', 8),\n",
       " ('drive', 6),\n",
       " ('go', 6),\n",
       " ('need', 6)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driving_GPT_topic_freq = Counter(driving_GPT_lem).most_common(10)\n",
    "driving_GPT_topic_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5904cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driving_topics = [topic[0] for topic in driving_topic_freq]\n",
    "driving_GPT_topics = [topic[0] for topic in driving_GPT_topic_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "25948831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['car', 'driverless', 'could', 'thing', 'driver', 'call', 'one', 'article', 'wrong', 'developement']\n",
      "['car', 'driverless', 'like', 'might', 'could', 'thing', 'road', 'drive', 'go', 'need']\n"
     ]
    }
   ],
   "source": [
    "print(driving_topics)\n",
    "print(driving_GPT_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37ffb40",
   "metadata": {},
   "source": [
    "Note, the first two topics are the same! The collection of \"topics\" have 5 elements in common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6fb659a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'car', 'driverless', 'thing', 'could'}\n"
     ]
    }
   ],
   "source": [
    "print(set(driving_topics).intersection(driving_GPT_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb973218",
   "metadata": {},
   "source": [
    "### Topic Distribution of Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c30fcf5",
   "metadata": {},
   "source": [
    "In this section, we determine the most common word from each essay. Considering the most common word as the \"topic\" of an essay allows us to calculate a distribution of topics, which we do below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e5781f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_word_freq = [Counter(topics).most_common(1)[0] for topics in lemmatized]\n",
    "top_word = [freq[0] for freq in top_word_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "68545c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15594 essays but only 397 \"topics\".\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(text_list)) + ' essays' + \\\n",
    "      ' but only ' + str(len(set(top_word))) + ' \"topics\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dfcb0a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'mar': 135,\n",
       "         'car': 2130,\n",
       "         'would': 446,\n",
       "         'student': 2406,\n",
       "         'animal': 33,\n",
       "         'venus': 749,\n",
       "         'phone': 783,\n",
       "         'school': 590,\n",
       "         'grade': 62,\n",
       "         'vote': 764,\n",
       "         'kid': 96,\n",
       "         'community': 357,\n",
       "         'face': 356,\n",
       "         'college': 58,\n",
       "         'person': 49,\n",
       "         'people': 563,\n",
       "         'policy': 36,\n",
       "         'driver': 28,\n",
       "         'system': 44,\n",
       "         'electoral': 484,\n",
       "         'opinion': 182,\n",
       "         'state': 152,\n",
       "         'computer': 79,\n",
       "         'ad': 2,\n",
       "         'still': 1,\n",
       "         'topic': 3,\n",
       "         'believe': 5,\n",
       "         'make': 47,\n",
       "         'author': 49,\n",
       "         'seagoing': 80,\n",
       "         'technology': 88,\n",
       "         'advice': 391,\n",
       "         'class': 160,\n",
       "         'need': 16,\n",
       "         'facial': 31,\n",
       "         'sport': 136,\n",
       "         'extracurricular': 14,\n",
       "         'get': 100,\n",
       "         'driving': 227,\n",
       "         'feel': 10,\n",
       "         'one': 88,\n",
       "         'could': 172,\n",
       "         'home': 35,\n",
       "         'right': 2,\n",
       "         'many': 13,\n",
       "         'job': 10,\n",
       "         'expression': 11,\n",
       "         'activity': 176,\n",
       "         'way': 18,\n",
       "         'planet': 54,\n",
       "         'others': 12,\n",
       "         'good': 30,\n",
       "         'use': 19,\n",
       "         'camera': 2,\n",
       "         'going': 11,\n",
       "         'texting': 5,\n",
       "         'decision': 54,\n",
       "         'elector': 48,\n",
       "         'facs': 11,\n",
       "         'alien': 104,\n",
       "         'service': 21,\n",
       "         'distance': 5,\n",
       "         'situation': 11,\n",
       "         'citizen': 4,\n",
       "         'project': 277,\n",
       "         'want': 38,\n",
       "         'ask': 49,\n",
       "         'work': 27,\n",
       "         'answer': 9,\n",
       "         'help': 193,\n",
       "         'made': 8,\n",
       "         'thing': 26,\n",
       "         'emotion': 102,\n",
       "         'idea': 19,\n",
       "         'even': 6,\n",
       "         'rock': 9,\n",
       "         'happy': 4,\n",
       "         'c': 13,\n",
       "         'luke': 96,\n",
       "         'think': 77,\n",
       "         'u': 34,\n",
       "         'choice': 56,\n",
       "         'trip': 6,\n",
       "         'invention': 1,\n",
       "         'software': 19,\n",
       "         'club': 17,\n",
       "         'pant': 1,\n",
       "         'time': 45,\n",
       "         'amount': 1,\n",
       "         'assignment': 8,\n",
       "         'reason': 17,\n",
       "         'cell': 40,\n",
       "         'president': 96,\n",
       "         'athlete': 2,\n",
       "         'attitude': 1,\n",
       "         'picture': 32,\n",
       "         'also': 18,\n",
       "         'multiple': 16,\n",
       "         'average': 60,\n",
       "         'agree': 1,\n",
       "         'join': 18,\n",
       "         'advantage': 2,\n",
       "         'like': 63,\n",
       "         'teacher': 32,\n",
       "         'classroom': 8,\n",
       "         'day': 8,\n",
       "         'different': 26,\n",
       "         'percent': 11,\n",
       "         'know': 26,\n",
       "         'got': 7,\n",
       "         'accident': 3,\n",
       "         'helping': 3,\n",
       "         'child': 13,\n",
       "         'really': 8,\n",
       "         'better': 16,\n",
       "         'new': 17,\n",
       "         'cowboy': 64,\n",
       "         'show': 1,\n",
       "         'talk': 1,\n",
       "         'said': 14,\n",
       "         'best': 5,\n",
       "         'someone': 17,\n",
       "         'sign': 2,\n",
       "         'say': 13,\n",
       "         'go': 25,\n",
       "         'something': 9,\n",
       "         'venis': 1,\n",
       "         'sea': 6,\n",
       "         'driverless': 12,\n",
       "         'mesa': 12,\n",
       "         'summer': 22,\n",
       "         'unfair': 1,\n",
       "         'program': 54,\n",
       "         'mood': 1,\n",
       "         'cellular': 1,\n",
       "         'natural': 15,\n",
       "         'mona': 3,\n",
       "         'study': 5,\n",
       "         'learning': 29,\n",
       "         'diffrent': 1,\n",
       "         'play': 19,\n",
       "         'online': 34,\n",
       "         'ther': 1,\n",
       "         'learn': 5,\n",
       "         'image': 4,\n",
       "         'voting': 12,\n",
       "         'machine': 3,\n",
       "         'theory': 1,\n",
       "         'test': 2,\n",
       "         'least': 1,\n",
       "         'sensor': 2,\n",
       "         'bored': 1,\n",
       "         'war': 2,\n",
       "         'congress': 2,\n",
       "         'advise': 9,\n",
       "         'johnny': 1,\n",
       "         'life': 11,\n",
       "         'robot': 1,\n",
       "         'may': 17,\n",
       "         'friend': 27,\n",
       "         'nasa': 25,\n",
       "         'look': 2,\n",
       "         'election': 13,\n",
       "         'interest': 1,\n",
       "         'world': 15,\n",
       "         'dress': 1,\n",
       "         'homework': 2,\n",
       "         'experience': 5,\n",
       "         'device': 3,\n",
       "         'country': 15,\n",
       "         'article': 2,\n",
       "         'water': 1,\n",
       "         'distracted': 1,\n",
       "         'floor': 1,\n",
       "         'city': 6,\n",
       "         'choose': 2,\n",
       "         'far': 1,\n",
       "         'human': 14,\n",
       "         'side': 2,\n",
       "         'valuable': 1,\n",
       "         'might': 13,\n",
       "         'understand': 1,\n",
       "         'injury': 1,\n",
       "         'feeling': 9,\n",
       "         'away': 2,\n",
       "         'autonimous': 1,\n",
       "         'muscle': 6,\n",
       "         'volunteer': 1,\n",
       "         'place': 8,\n",
       "         'never': 2,\n",
       "         'cellphone': 5,\n",
       "         'road': 2,\n",
       "         'adventure': 1,\n",
       "         'rule': 8,\n",
       "         'information': 2,\n",
       "         'wo': 1,\n",
       "         'great': 6,\n",
       "         'guardian': 1,\n",
       "         'drive': 3,\n",
       "         'voter': 3,\n",
       "         'convince': 1,\n",
       "         'team': 12,\n",
       "         'point': 1,\n",
       "         'landform': 23,\n",
       "         'read': 4,\n",
       "         'see': 13,\n",
       "         'earth': 9,\n",
       "         'real': 1,\n",
       "         'shadow': 1,\n",
       "         'letter': 2,\n",
       "         'process': 2,\n",
       "         'tell': 8,\n",
       "         'formation': 6,\n",
       "         'course': 2,\n",
       "         'fun': 8,\n",
       "         'asking': 9,\n",
       "         'problem': 7,\n",
       "         'plant': 1,\n",
       "         'alot': 3,\n",
       "         'maybe': 3,\n",
       "         'figure': 1,\n",
       "         'pollution': 1,\n",
       "         'went': 1,\n",
       "         'listen': 2,\n",
       "         'cattle': 1,\n",
       "         'subject': 2,\n",
       "         'horse': 2,\n",
       "         'vehicle': 9,\n",
       "         'option': 6,\n",
       "         'start': 1,\n",
       "         'foot': 1,\n",
       "         'candidate': 3,\n",
       "         'tool': 1,\n",
       "         'computor': 2,\n",
       "         'curricular': 1,\n",
       "         'text': 2,\n",
       "         'collage': 2,\n",
       "         'win': 1,\n",
       "         'space': 2,\n",
       "         'coyboy': 1,\n",
       "         'dont': 7,\n",
       "         'brother': 1,\n",
       "         'movement': 1,\n",
       "         'partner': 1,\n",
       "         'video': 4,\n",
       "         'money': 3,\n",
       "         'everyone': 4,\n",
       "         'chose': 1,\n",
       "         'scan': 1,\n",
       "         'principal': 1,\n",
       "         'sould': 1,\n",
       "         'attend': 2,\n",
       "         'change': 4,\n",
       "         'used': 2,\n",
       "         'care': 2,\n",
       "         'le': 9,\n",
       "         'method': 4,\n",
       "         'europe': 1,\n",
       "         'give': 1,\n",
       "         'necklace': 1,\n",
       "         'excellent': 1,\n",
       "         'differnt': 1,\n",
       "         'well': 5,\n",
       "         'litter': 2,\n",
       "         'gas': 1,\n",
       "         'education': 1,\n",
       "         'skill': 2,\n",
       "         'imagine': 1,\n",
       "         'government': 2,\n",
       "         'extra': 2,\n",
       "         'nobody': 1,\n",
       "         'take': 3,\n",
       "         'region': 1,\n",
       "         'land': 1,\n",
       "         'wan': 2,\n",
       "         'programe': 1,\n",
       "         'canidate': 1,\n",
       "         'icon': 1,\n",
       "         'paragraph': 2,\n",
       "         'pair': 1,\n",
       "         'source': 3,\n",
       "         'american': 1,\n",
       "         'thier': 1,\n",
       "         'smile': 2,\n",
       "         'scientist': 4,\n",
       "         'development': 1,\n",
       "         'book': 1,\n",
       "         'b': 6,\n",
       "         'able': 8,\n",
       "         'benefit': 1,\n",
       "         'landfrom': 1,\n",
       "         'gym': 1,\n",
       "         'soccer': 2,\n",
       "         'hard': 1,\n",
       "         'prodject': 1,\n",
       "         'court': 1,\n",
       "         'try': 2,\n",
       "         'lot': 1,\n",
       "         'somebody': 1,\n",
       "         'several': 1,\n",
       "         'come': 1,\n",
       "         'joe': 1,\n",
       "         'support': 1,\n",
       "         'participate': 1,\n",
       "         'gut': 1,\n",
       "         'surface': 1,\n",
       "         'talking': 1,\n",
       "         'colledge': 1,\n",
       "         'always': 2,\n",
       "         'essay': 1,\n",
       "         'game': 2,\n",
       "         'probably': 1,\n",
       "         'group': 1,\n",
       "         'chance': 1,\n",
       "         'career': 1,\n",
       "         'hour': 1,\n",
       "         'let': 2,\n",
       "         'photo': 6,\n",
       "         'boring': 1,\n",
       "         'question': 1,\n",
       "         'emotional': 2,\n",
       "         'run': 1,\n",
       "         'im': 1,\n",
       "         'alian': 1,\n",
       "         'research': 1,\n",
       "         'venue': 1,\n",
       "         'health': 1,\n",
       "         'family': 1,\n",
       "         'amazing': 1,\n",
       "         'mobile': 1,\n",
       "         'cause': 1,\n",
       "         'seegoing': 1,\n",
       "         'america': 1,\n",
       "         'peolpe': 1,\n",
       "         'attending': 1,\n",
       "         'view': 1,\n",
       "         'little': 1,\n",
       "         'find': 1,\n",
       "         'teenager': 2,\n",
       "         'promblem': 1,\n",
       "         'belive': 1,\n",
       "         'detroit': 1,\n",
       "         'thought': 1,\n",
       "         'business': 1,\n",
       "         'ball': 1,\n",
       "         'coding': 1,\n",
       "         'halt': 1,\n",
       "         'pterodactyl': 1,\n",
       "         'venuse': 2,\n",
       "         'nassa': 1,\n",
       "         'tecnology': 1,\n",
       "         'took': 1,\n",
       "         'every': 1,\n",
       "         'step': 1,\n",
       "         'lake': 1,\n",
       "         'jacob': 1,\n",
       "         'started': 1,\n",
       "         'law': 2,\n",
       "         'apart': 1,\n",
       "         'thay': 1,\n",
       "         'helpful': 1,\n",
       "         'feedback': 1,\n",
       "         'vehicals': 1,\n",
       "         'thats': 1,\n",
       "         'bring': 1,\n",
       "         'football': 1,\n",
       "         'hit': 1,\n",
       "         'mom': 2,\n",
       "         'landforms': 1,\n",
       "         'zeke': 1,\n",
       "         'plan': 1,\n",
       "         'raven': 1,\n",
       "         'electorial': 2,\n",
       "         'hear': 1,\n",
       "         'dog': 1,\n",
       "         'color': 1,\n",
       "         'proof': 1,\n",
       "         'unrra': 1,\n",
       "         'period': 1,\n",
       "         'town': 2,\n",
       "         'example': 1,\n",
       "         'luck': 1,\n",
       "         'limiting': 1,\n",
       "         'viking': 1,\n",
       "         'issue': 1,\n",
       "         'alliens': 1,\n",
       "         'danger': 1,\n",
       "         'bobby': 1,\n",
       "         'report': 1,\n",
       "         'spacecraft': 1,\n",
       "         'evidence': 1,\n",
       "         'app': 1,\n",
       "         'two': 1,\n",
       "         'driveless': 1,\n",
       "         'mineral': 1,\n",
       "         'created': 1,\n",
       "         'mad': 1})"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of topics\n",
    "Counter(top_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "fe80a966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('student', 0.154)\n",
      "('car', 0.137)\n",
      "('phone', 0.05)\n",
      "('vote', 0.049)\n",
      "('venus', 0.048)\n",
      "('school', 0.038)\n",
      "('people', 0.036)\n",
      "('electoral', 0.031)\n",
      "('would', 0.029)\n",
      "('advice', 0.025)\n",
      "('community', 0.023)\n",
      "('face', 0.023)\n",
      "('project', 0.018)\n",
      "('driving', 0.015)\n",
      "('opinion', 0.012)\n",
      "('help', 0.012)\n",
      "('could', 0.011)\n",
      "('activity', 0.011)\n",
      "('state', 0.01)\n",
      "('class', 0.01)\n",
      "('mar', 0.009)\n",
      "('sport', 0.009)\n",
      "('alien', 0.007)\n",
      "('emotion', 0.007)\n",
      "('kid', 0.006)\n",
      "('technology', 0.006)\n",
      "('get', 0.006)\n",
      "('one', 0.006)\n",
      "('luke', 0.006)\n",
      "('president', 0.006)\n",
      "('computer', 0.005)\n",
      "('seagoing', 0.005)\n",
      "('think', 0.005)\n",
      "('grade', 0.004)\n",
      "('college', 0.004)\n",
      "('choice', 0.004)\n",
      "('average', 0.004)\n",
      "('like', 0.004)\n",
      "('cowboy', 0.004)\n",
      "('person', 0.003)\n",
      "('system', 0.003)\n",
      "('make', 0.003)\n",
      "('author', 0.003)\n",
      "('planet', 0.003)\n",
      "('decision', 0.003)\n",
      "('elector', 0.003)\n",
      "('ask', 0.003)\n",
      "('time', 0.003)\n",
      "('cell', 0.003)\n",
      "('program', 0.003)\n",
      "('animal', 0.002)\n",
      "('policy', 0.002)\n",
      "('driver', 0.002)\n",
      "('facial', 0.002)\n",
      "('home', 0.002)\n",
      "('good', 0.002)\n",
      "('want', 0.002)\n",
      "('work', 0.002)\n",
      "('thing', 0.002)\n",
      "('u', 0.002)\n",
      "('picture', 0.002)\n",
      "('teacher', 0.002)\n",
      "('different', 0.002)\n",
      "('know', 0.002)\n",
      "('go', 0.002)\n",
      "('learning', 0.002)\n",
      "('online', 0.002)\n",
      "('friend', 0.002)\n",
      "('nasa', 0.002)\n",
      "('need', 0.001)\n",
      "('extracurricular', 0.001)\n",
      "('feel', 0.001)\n",
      "('many', 0.001)\n",
      "('job', 0.001)\n",
      "('expression', 0.001)\n",
      "('way', 0.001)\n",
      "('others', 0.001)\n",
      "('use', 0.001)\n",
      "('going', 0.001)\n",
      "('facs', 0.001)\n",
      "('service', 0.001)\n",
      "('situation', 0.001)\n",
      "('answer', 0.001)\n",
      "('made', 0.001)\n",
      "('idea', 0.001)\n",
      "('rock', 0.001)\n",
      "('c', 0.001)\n",
      "('software', 0.001)\n",
      "('club', 0.001)\n",
      "('assignment', 0.001)\n",
      "('reason', 0.001)\n",
      "('also', 0.001)\n",
      "('multiple', 0.001)\n",
      "('join', 0.001)\n",
      "('classroom', 0.001)\n",
      "('day', 0.001)\n",
      "('percent', 0.001)\n",
      "('child', 0.001)\n",
      "('really', 0.001)\n",
      "('better', 0.001)\n",
      "('new', 0.001)\n",
      "('said', 0.001)\n",
      "('someone', 0.001)\n",
      "('say', 0.001)\n",
      "('something', 0.001)\n",
      "('driverless', 0.001)\n",
      "('mesa', 0.001)\n",
      "('summer', 0.001)\n",
      "('natural', 0.001)\n",
      "('play', 0.001)\n",
      "('voting', 0.001)\n",
      "('advise', 0.001)\n",
      "('life', 0.001)\n",
      "('may', 0.001)\n",
      "('election', 0.001)\n",
      "('world', 0.001)\n",
      "('country', 0.001)\n",
      "('human', 0.001)\n",
      "('might', 0.001)\n",
      "('feeling', 0.001)\n",
      "('place', 0.001)\n",
      "('rule', 0.001)\n",
      "('team', 0.001)\n",
      "('landform', 0.001)\n",
      "('see', 0.001)\n",
      "('earth', 0.001)\n",
      "('tell', 0.001)\n",
      "('fun', 0.001)\n",
      "('asking', 0.001)\n",
      "('vehicle', 0.001)\n",
      "('le', 0.001)\n",
      "('able', 0.001)\n",
      "('ad', 0.0)\n",
      "('still', 0.0)\n",
      "('topic', 0.0)\n",
      "('believe', 0.0)\n",
      "('right', 0.0)\n",
      "('camera', 0.0)\n",
      "('texting', 0.0)\n",
      "('distance', 0.0)\n",
      "('citizen', 0.0)\n",
      "('even', 0.0)\n",
      "('happy', 0.0)\n",
      "('trip', 0.0)\n",
      "('invention', 0.0)\n",
      "('pant', 0.0)\n",
      "('amount', 0.0)\n",
      "('athlete', 0.0)\n",
      "('attitude', 0.0)\n",
      "('agree', 0.0)\n",
      "('advantage', 0.0)\n",
      "('got', 0.0)\n",
      "('accident', 0.0)\n",
      "('helping', 0.0)\n",
      "('show', 0.0)\n",
      "('talk', 0.0)\n",
      "('best', 0.0)\n",
      "('sign', 0.0)\n",
      "('venis', 0.0)\n",
      "('sea', 0.0)\n",
      "('unfair', 0.0)\n",
      "('mood', 0.0)\n",
      "('cellular', 0.0)\n",
      "('mona', 0.0)\n",
      "('study', 0.0)\n",
      "('diffrent', 0.0)\n",
      "('ther', 0.0)\n",
      "('learn', 0.0)\n",
      "('image', 0.0)\n",
      "('machine', 0.0)\n",
      "('theory', 0.0)\n",
      "('test', 0.0)\n",
      "('least', 0.0)\n",
      "('sensor', 0.0)\n",
      "('bored', 0.0)\n",
      "('war', 0.0)\n",
      "('congress', 0.0)\n",
      "('johnny', 0.0)\n",
      "('robot', 0.0)\n",
      "('look', 0.0)\n",
      "('interest', 0.0)\n",
      "('dress', 0.0)\n",
      "('homework', 0.0)\n",
      "('experience', 0.0)\n",
      "('device', 0.0)\n",
      "('article', 0.0)\n",
      "('water', 0.0)\n",
      "('distracted', 0.0)\n",
      "('floor', 0.0)\n",
      "('city', 0.0)\n",
      "('choose', 0.0)\n",
      "('far', 0.0)\n",
      "('side', 0.0)\n",
      "('valuable', 0.0)\n",
      "('understand', 0.0)\n",
      "('injury', 0.0)\n",
      "('away', 0.0)\n",
      "('autonimous', 0.0)\n",
      "('muscle', 0.0)\n",
      "('volunteer', 0.0)\n",
      "('never', 0.0)\n",
      "('cellphone', 0.0)\n",
      "('road', 0.0)\n",
      "('adventure', 0.0)\n",
      "('information', 0.0)\n",
      "('wo', 0.0)\n",
      "('great', 0.0)\n",
      "('guardian', 0.0)\n",
      "('drive', 0.0)\n",
      "('voter', 0.0)\n",
      "('convince', 0.0)\n",
      "('point', 0.0)\n",
      "('read', 0.0)\n",
      "('real', 0.0)\n",
      "('shadow', 0.0)\n",
      "('letter', 0.0)\n",
      "('process', 0.0)\n",
      "('formation', 0.0)\n",
      "('course', 0.0)\n",
      "('problem', 0.0)\n",
      "('plant', 0.0)\n",
      "('alot', 0.0)\n",
      "('maybe', 0.0)\n",
      "('figure', 0.0)\n",
      "('pollution', 0.0)\n",
      "('went', 0.0)\n",
      "('listen', 0.0)\n",
      "('cattle', 0.0)\n",
      "('subject', 0.0)\n",
      "('horse', 0.0)\n",
      "('option', 0.0)\n",
      "('start', 0.0)\n",
      "('foot', 0.0)\n",
      "('candidate', 0.0)\n",
      "('tool', 0.0)\n",
      "('computor', 0.0)\n",
      "('curricular', 0.0)\n",
      "('text', 0.0)\n",
      "('collage', 0.0)\n",
      "('win', 0.0)\n",
      "('space', 0.0)\n",
      "('coyboy', 0.0)\n",
      "('dont', 0.0)\n",
      "('brother', 0.0)\n",
      "('movement', 0.0)\n",
      "('partner', 0.0)\n",
      "('video', 0.0)\n",
      "('money', 0.0)\n",
      "('everyone', 0.0)\n",
      "('chose', 0.0)\n",
      "('scan', 0.0)\n",
      "('principal', 0.0)\n",
      "('sould', 0.0)\n",
      "('attend', 0.0)\n",
      "('change', 0.0)\n",
      "('used', 0.0)\n",
      "('care', 0.0)\n",
      "('method', 0.0)\n",
      "('europe', 0.0)\n",
      "('give', 0.0)\n",
      "('necklace', 0.0)\n",
      "('excellent', 0.0)\n",
      "('differnt', 0.0)\n",
      "('well', 0.0)\n",
      "('litter', 0.0)\n",
      "('gas', 0.0)\n",
      "('education', 0.0)\n",
      "('skill', 0.0)\n",
      "('imagine', 0.0)\n",
      "('government', 0.0)\n",
      "('extra', 0.0)\n",
      "('nobody', 0.0)\n",
      "('take', 0.0)\n",
      "('region', 0.0)\n",
      "('land', 0.0)\n",
      "('wan', 0.0)\n",
      "('programe', 0.0)\n",
      "('canidate', 0.0)\n",
      "('icon', 0.0)\n",
      "('paragraph', 0.0)\n",
      "('pair', 0.0)\n",
      "('source', 0.0)\n",
      "('american', 0.0)\n",
      "('thier', 0.0)\n",
      "('smile', 0.0)\n",
      "('scientist', 0.0)\n",
      "('development', 0.0)\n",
      "('book', 0.0)\n",
      "('b', 0.0)\n",
      "('benefit', 0.0)\n",
      "('landfrom', 0.0)\n",
      "('gym', 0.0)\n",
      "('soccer', 0.0)\n",
      "('hard', 0.0)\n",
      "('prodject', 0.0)\n",
      "('court', 0.0)\n",
      "('try', 0.0)\n",
      "('lot', 0.0)\n",
      "('somebody', 0.0)\n",
      "('several', 0.0)\n",
      "('come', 0.0)\n",
      "('joe', 0.0)\n",
      "('support', 0.0)\n",
      "('participate', 0.0)\n",
      "('gut', 0.0)\n",
      "('surface', 0.0)\n",
      "('talking', 0.0)\n",
      "('colledge', 0.0)\n",
      "('always', 0.0)\n",
      "('essay', 0.0)\n",
      "('game', 0.0)\n",
      "('probably', 0.0)\n",
      "('group', 0.0)\n",
      "('chance', 0.0)\n",
      "('career', 0.0)\n",
      "('hour', 0.0)\n",
      "('let', 0.0)\n",
      "('photo', 0.0)\n",
      "('boring', 0.0)\n",
      "('question', 0.0)\n",
      "('emotional', 0.0)\n",
      "('run', 0.0)\n",
      "('im', 0.0)\n",
      "('alian', 0.0)\n",
      "('research', 0.0)\n",
      "('venue', 0.0)\n",
      "('health', 0.0)\n",
      "('family', 0.0)\n",
      "('amazing', 0.0)\n",
      "('mobile', 0.0)\n",
      "('cause', 0.0)\n",
      "('seegoing', 0.0)\n",
      "('america', 0.0)\n",
      "('peolpe', 0.0)\n",
      "('attending', 0.0)\n",
      "('view', 0.0)\n",
      "('little', 0.0)\n",
      "('find', 0.0)\n",
      "('teenager', 0.0)\n",
      "('promblem', 0.0)\n",
      "('belive', 0.0)\n",
      "('detroit', 0.0)\n",
      "('thought', 0.0)\n",
      "('business', 0.0)\n",
      "('ball', 0.0)\n",
      "('coding', 0.0)\n",
      "('halt', 0.0)\n",
      "('pterodactyl', 0.0)\n",
      "('venuse', 0.0)\n",
      "('nassa', 0.0)\n",
      "('tecnology', 0.0)\n",
      "('took', 0.0)\n",
      "('every', 0.0)\n",
      "('step', 0.0)\n",
      "('lake', 0.0)\n",
      "('jacob', 0.0)\n",
      "('started', 0.0)\n",
      "('law', 0.0)\n",
      "('apart', 0.0)\n",
      "('thay', 0.0)\n",
      "('helpful', 0.0)\n",
      "('feedback', 0.0)\n",
      "('vehicals', 0.0)\n",
      "('thats', 0.0)\n",
      "('bring', 0.0)\n",
      "('football', 0.0)\n",
      "('hit', 0.0)\n",
      "('mom', 0.0)\n",
      "('landforms', 0.0)\n",
      "('zeke', 0.0)\n",
      "('plan', 0.0)\n",
      "('raven', 0.0)\n",
      "('electorial', 0.0)\n",
      "('hear', 0.0)\n",
      "('dog', 0.0)\n",
      "('color', 0.0)\n",
      "('proof', 0.0)\n",
      "('unrra', 0.0)\n",
      "('period', 0.0)\n",
      "('town', 0.0)\n",
      "('example', 0.0)\n",
      "('luck', 0.0)\n",
      "('limiting', 0.0)\n",
      "('viking', 0.0)\n",
      "('issue', 0.0)\n",
      "('alliens', 0.0)\n",
      "('danger', 0.0)\n",
      "('bobby', 0.0)\n",
      "('report', 0.0)\n",
      "('spacecraft', 0.0)\n",
      "('evidence', 0.0)\n",
      "('app', 0.0)\n",
      "('two', 0.0)\n",
      "('driveless', 0.0)\n",
      "('mineral', 0.0)\n",
      "('created', 0.0)\n",
      "('mad', 0.0)\n"
     ]
    }
   ],
   "source": [
    "#normalized distribution of topics\n",
    "\n",
    "total = len(text_list)\n",
    "topic_dist = [(topic, round(count/total,3)) for topic, count in Counter(top_word).items()]\n",
    "topic_dist = sorted(topic_dist, key = lambda topic: topic[1], reverse = True)\n",
    "\n",
    "for topic in topic_dist:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f6377",
   "metadata": {},
   "source": [
    "The most common topic is \"student\". Now we look at the second most common word among the essays whose topic is \"student\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "ac6d78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_word_freq = [Counter(topics).most_common(10)[1] for topics in lemmatized \\\n",
    "                   if Counter(topics).most_common(1)[0][0] == 'student']\n",
    "\n",
    "student_word = [freq[0] for freq in student_word_freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5bc5e6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2406 essays with a top word of \"student\" but only 163 \"sub-topics\" among them.\n"
     ]
    }
   ],
   "source": [
    "print('There are ' + str(len(student_word)) + ' essays with a top word of \"student\"' + \\\n",
    "      ' but only ' + str(len(set(student_word))) + ' \"sub-topics\" among them.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "6d504a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('school', 398),\n",
       " ('project', 332),\n",
       " ('class', 171),\n",
       " ('would', 136),\n",
       " ('activity', 125),\n",
       " ('teacher', 97),\n",
       " ('learning', 83),\n",
       " ('online', 78),\n",
       " ('home', 67),\n",
       " ('community', 66),\n",
       " ('phone', 64),\n",
       " ('summer', 57),\n",
       " ('could', 48),\n",
       " ('sport', 45),\n",
       " ('help', 37),\n",
       " ('work', 35),\n",
       " ('technology', 29),\n",
       " ('grade', 25),\n",
       " ('time', 22),\n",
       " ('average', 19)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(student_word).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dbdceaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('school', 0.165)\n",
      "('project', 0.138)\n",
      "('class', 0.071)\n",
      "('would', 0.057)\n",
      "('activity', 0.052)\n",
      "('teacher', 0.04)\n",
      "('learning', 0.034)\n",
      "('online', 0.032)\n",
      "('home', 0.028)\n",
      "('phone', 0.027)\n",
      "('community', 0.027)\n",
      "('summer', 0.024)\n",
      "('could', 0.02)\n",
      "('sport', 0.019)\n",
      "('help', 0.015)\n",
      "('work', 0.015)\n",
      "('technology', 0.012)\n",
      "('grade', 0.01)\n",
      "('time', 0.009)\n",
      "('average', 0.008)\n",
      "('assignment', 0.007)\n",
      "('may', 0.007)\n",
      "('emotion', 0.007)\n",
      "('cell', 0.007)\n",
      "('extracurricular', 0.007)\n",
      "('classroom', 0.007)\n",
      "('policy', 0.006)\n",
      "('learn', 0.005)\n",
      "('computer', 0.005)\n",
      "('get', 0.005)\n",
      "('think', 0.004)\n",
      "('system', 0.004)\n",
      "('c', 0.004)\n",
      "('like', 0.004)\n",
      "('distance', 0.003)\n",
      "('want', 0.003)\n",
      "('many', 0.003)\n",
      "('topic', 0.003)\n",
      "('club', 0.002)\n",
      "('need', 0.002)\n",
      "('one', 0.002)\n",
      "('new', 0.002)\n",
      "('might', 0.002)\n",
      "('program', 0.002)\n",
      "('facial', 0.002)\n",
      "('kid', 0.002)\n",
      "('education', 0.002)\n",
      "('know', 0.002)\n",
      "('play', 0.002)\n",
      "('lesson', 0.002)\n",
      "('software', 0.002)\n",
      "('make', 0.002)\n",
      "('child', 0.002)\n",
      "('expression', 0.002)\n",
      "('also', 0.002)\n",
      "('facs', 0.002)\n",
      "('able', 0.002)\n",
      "('friend', 0.002)\n",
      "('family', 0.001)\n",
      "('feeling', 0.001)\n",
      "('skill', 0.001)\n",
      "('parent', 0.001)\n",
      "('feel', 0.001)\n",
      "('going', 0.001)\n",
      "('change', 0.001)\n",
      "('good', 0.001)\n",
      "('rule', 0.001)\n",
      "('dont', 0.001)\n",
      "('distant', 0.001)\n",
      "('u', 0.001)\n",
      "('better', 0.001)\n",
      "('thing', 0.001)\n",
      "('service', 0.001)\n",
      "('break', 0.001)\n",
      "('life', 0.001)\n",
      "('participate', 0.001)\n",
      "('way', 0.001)\n",
      "('course', 0.001)\n",
      "('setting', 0.001)\n",
      "('use', 0.001)\n",
      "('choice', 0.001)\n",
      "('design', 0.001)\n",
      "('attend', 0.001)\n",
      "('people', 0.001)\n",
      "('ad', 0.001)\n",
      "('designed', 0.001)\n",
      "('give', 0.001)\n",
      "('machine', 0.001)\n",
      "('video', 0.001)\n",
      "('decision', 0.001)\n",
      "('idea', 0.001)\n",
      "('mona', 0.0)\n",
      "('valuable', 0.0)\n",
      "('well', 0.0)\n",
      "('respect', 0.0)\n",
      "('wo', 0.0)\n",
      "('confused', 0.0)\n",
      "('prompt', 0.0)\n",
      "('go', 0.0)\n",
      "('yearbook', 0.0)\n",
      "('face', 0.0)\n",
      "('staff', 0.0)\n",
      "('something', 0.0)\n",
      "('item', 0.0)\n",
      "('principal', 0.0)\n",
      "('coding', 0.0)\n",
      "('social', 0.0)\n",
      "('issue', 0.0)\n",
      "('bring', 0.0)\n",
      "('different', 0.0)\n",
      "('emotional', 0.0)\n",
      "('tool', 0.0)\n",
      "('schooling', 0.0)\n",
      "('virus', 0.0)\n",
      "('planet', 0.0)\n",
      "('first', 0.0)\n",
      "('problem', 0.0)\n",
      "('college', 0.0)\n",
      "('emotionals', 0.0)\n",
      "('month', 0.0)\n",
      "('reason', 0.0)\n",
      "('allowed', 0.0)\n",
      "('show', 0.0)\n",
      "('every', 0.0)\n",
      "('son', 0.0)\n",
      "('say', 0.0)\n",
      "('group', 0.0)\n",
      "('fun', 0.0)\n",
      "('letter', 0.0)\n",
      "('afterschool', 0.0)\n",
      "('someone', 0.0)\n",
      "('read', 0.0)\n",
      "('collage', 0.0)\n",
      "('huang', 0.0)\n",
      "('right', 0.0)\n",
      "('understand', 0.0)\n",
      "('part', 0.0)\n",
      "('sad', 0.0)\n",
      "('year', 0.0)\n",
      "('lunch', 0.0)\n",
      "('option', 0.0)\n",
      "('really', 0.0)\n",
      "('understanding', 0.0)\n",
      "('others', 0.0)\n",
      "('earth', 0.0)\n",
      "('team', 0.0)\n",
      "('athlete', 0.0)\n",
      "('teen', 0.0)\n",
      "('hard', 0.0)\n",
      "('gym', 0.0)\n",
      "('exercise', 0.0)\n",
      "('appointment', 0.0)\n",
      "('bad', 0.0)\n",
      "('book', 0.0)\n",
      "('subject', 0.0)\n",
      "('long', 0.0)\n",
      "('best', 0.0)\n",
      "('type', 0.0)\n",
      "('suppose', 0.0)\n",
      "('distraction', 0.0)\n",
      "('extra', 0.0)\n",
      "('put', 0.0)\n",
      "('sleep', 0.0)\n"
     ]
    }
   ],
   "source": [
    "total = len(student_word)\n",
    "topic_dist = [(topic, round(count/total,3)) for topic, count in Counter(student_word).items()]\n",
    "topic_dist = sorted(topic_dist, key = lambda topic: topic[1], reverse = True)\n",
    "\n",
    "for topic in topic_dist:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a587f3",
   "metadata": {},
   "source": [
    "This analysis shows that essay topics are far from uniformly distributed and are biased toward things you might students in grades 6-12 would right about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddb8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
