{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3286b9c7-867a-47f5-8bc5-e2747e6d7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "from pytorch_model import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad7553c-ae55-4549-9e59-a8c198bbdefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "16  CPUs available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print(mp.cpu_count(),' CPUs available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb76a4-a999-4d77-85cf-6c90071d1287",
   "metadata": {},
   "source": [
    "## Saving/Loading a pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee337dc6-cf86-4352-b3a4-795cc27bfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model0 = Classifier(use_LSTM=True,N_metrics=5)\n",
    "#model0 = model0.to(device)# put it on gpu\n",
    "\n",
    "# save some test model weights\n",
    "model_weights_path = 'training/model_weights_rand.pt'\n",
    "torch.save(model0.state_dict(), model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27351d05-deec-4ca6-93aa-53955f727260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (text_read): LSTM(300, 128)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=133, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a new model with the exact same architecture\n",
    "model  = Classifier(use_LSTM=True,N_metrics=5)\n",
    "\n",
    "# load it\n",
    "model_weights_path = 'training/model_weights_rand.pt'\n",
    "model.load_state_dict(torch.load(model_weights_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aaa6ba-dad6-467a-8272-e64555597378",
   "metadata": {},
   "source": [
    "## Inputting text to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199864ff-6a9d-473c-8bdc-b9ab84af8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_test = \"\"\"My Amazing Adventure to Mars: The Search for Aliens and the Mysterious Face\n",
    "Hey there, fellow explorers! Let me tell you about this incredible journey to Mars. Imagine a planet with red deserts and rocky landscapes, where scientists from NASA are sending cool rovers to find signs of life. And guess what? There's this mysterious mesa that people used to think looked like a giant face!\n",
    "Back in 1976, NASA's Viking 1 spacecraft sent back a picture of a mesa on Mars that everyone thought was a face. It was like something out of a sci-fi movie! But later, when newer pictures came in, the face turned out to be just a funny-shaped hill. Still, the idea of finding a face on another planet got everyone super excited.\n",
    "Now, why are we so obsessed with Mars? Well, NASA believes there might be tiny living things, like microbes, hiding under the surface or in old Martian lakes. How cool would that be? It's like playing hide and seek with aliens on a whole other planet!\n",
    "The rovers NASA created, like Curiosity, are like our robotic buddies exploring Mars for us. These machines are super smart and have all sorts of tools to dig, sniff, and take awesome pictures. They're like our interplanetary detectives, searching for clues that could tell us if Mars ever had or still has any form of life.\n",
    "Just think about it – if those rovers found even the tiniest hint of life on Mars, it would be mind-blowing! It would mean that we're not alone in this vast universe. It would be like discovering a whole new neighborhood of alien neighbors.\n",
    "But getting to Mars and sending these cool rovers isn't easy. It takes a lot of brainpower from scientists and engineers who design and build these amazing space machines. They're like the superheroes of space exploration, using their smarts to unlock the secrets of the universe.\n",
    "The idea of aliens has always been a big mystery that sparks our imagination. We wonder what they might look like and if they're friendly or not. Finding life on Mars would be like making friends with aliens, and that's just awesome to think about!\n",
    "So, here's to the brave people at NASA and their rovers, exploring Mars and searching for signs of life. Who knows what they might discover next? Maybe they'll find something even cooler than a face – maybe they'll find our future Martian pals! It's like the best space adventure ever, and we're all a part of it, dreaming big and reaching for the stars.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0cef0d-56eb-4ce9-a999-74c86e343ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Amazing Adventure to Mars: The Search for Aliens and the Mysterious Face\n",
      "Hey there, fellow explorers! Let me tell you about this incredible journey to Mars. Imagine a planet with red deserts and rocky landscapes, where scientists from NASA are sending cool rovers to find signs of life. And guess what? There's this mysterious mesa that people used to think looked like a giant face!\n",
      "Back in 1976, NASA's Viking 1 spacecraft sent back a picture of a mesa on Mars that everyone thought was a face. It was like something out of a sci-fi movie! But later, when newer pictures came in, the face turned out to be just a funny-shaped hill. Still, the idea of finding a face on another planet got everyone super excited.\n",
      "Now, why are we so obsessed with Mars? Well, NASA believes there might be tiny living things, like microbes, hiding under the surface or in old Martian lakes. How cool would that be? It's like playing hide and seek with aliens on a whole other planet!\n",
      "The rovers NASA created, like Curiosity, are like our robotic buddies exploring Mars for us. These machines are super smart and have all sorts of tools to dig, sniff, and take awesome pictures. They're like our interplanetary detectives, searching for clues that could tell us if Mars ever had or still has any form of life.\n",
      "Just think about it – if those rovers found even the tiniest hint of life on Mars, it would be mind-blowing! It would mean that we're not alone in this vast universe. It would be like discovering a whole new neighborhood of alien neighbors.\n",
      "But getting to Mars and sending these cool rovers isn't easy. It takes a lot of brainpower from scientists and engineers who design and build these amazing space machines. They're like the superheroes of space exploration, using their smarts to unlock the secrets of the universe.\n",
      "The idea of aliens has always been a big mystery that sparks our imagination. We wonder what they might look like and if they're friendly or not. Finding life on Mars would be like making friends with aliens, and that's just awesome to think about!\n",
      "So, here's to the brave people at NASA and their rovers, exploring Mars and searching for signs of life. Who knows what they might discover next? Maybe they'll find something even cooler than a face – maybe they'll find our future Martian pals! It's like the best space adventure ever, and we're all a part of it, dreaming big and reaching for the stars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(input_text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ffc6e-e993-49e0-9c8e-11f334fb1d2d",
   "metadata": {},
   "source": [
    "### We need to do a little preprocessing \n",
    "\n",
    "(it might take a bit for some things to load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74707e0d-f73c-4696-83cf-e2e986c1d850",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rachel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rachel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/rachel/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from preprocessing import preprocess,  metrics, w2v\n",
    "remap = {'a':'an', 'and':'also', 'of':'in', 'to':'at'}\n",
    "\n",
    "def process_for_model(text):\n",
    "    # extract metrics then do preprocessing\n",
    "    met = metrics(text)\n",
    "    \n",
    "    # do some processing \n",
    "    proc = preprocess(text)\n",
    "    processed_text_words = proc.split()# split by whitespace\n",
    "    essay_words = [remap[word] if word in remap.keys() else word for word in processed_text_words]\n",
    "    \n",
    "    # do word2vec\n",
    "    vecs = []\n",
    "    missing_words =[]\n",
    "    for word in essay_words:\n",
    "        try:\n",
    "            vec = w2v.get_vector(word)\n",
    "            vecs.append(vec)\n",
    "        except KeyError:\n",
    "            # this means that the word isn't in the w2v\n",
    "            missing_words.append(word)\n",
    "    vecs = np.array(vecs)\n",
    "    \n",
    "\n",
    "    #print all the words that are missing\n",
    "    unique_missing =  \" \".join(list(np.unique(np.array(missing_words))))\n",
    "    print('missing these words in model: ',unique_missing)\n",
    "    \n",
    "    torch_tensor = torch.from_numpy(vecs).reshape(-1,300)\n",
    "    torch_met = torch.from_numpy(met).float()\n",
    "    return torch_tensor, torch_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f0e2bb-2e1c-4176-affe-16e3f152bddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing these words in model:  \n",
      "CPU times: user 69.8 ms, sys: 20 ms, total: 89.8 ms\n",
      "Wall time: 88.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tensor,metrics = process_for_model(input_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f42b516f-94cc-4229-9f4e-ac446ef552f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1445,  0.0471,  0.1006,  ...,  0.0023,  0.0981, -0.0669],\n",
       "         [ 0.0737,  0.0041, -0.1357,  ..., -0.1416, -0.1504, -0.1377],\n",
       "         [ 0.2002, -0.0197, -0.1357,  ...,  0.0928,  0.2012,  0.1318],\n",
       "         ...,\n",
       "         [-0.0118, -0.0474,  0.0447,  ...,  0.0713, -0.0349,  0.0242],\n",
       "         [ 0.0801,  0.1050,  0.0498,  ...,  0.0037,  0.0476, -0.0688],\n",
       "         [-0.0184,  0.1709,  0.1108,  ..., -0.1348, -0.0162,  0.0167]]),\n",
       " torch.Size([449, 300]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0c8a94f-f85a-4468-bb10-22520e99cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.3545e+01, 2.4300e-01, 2.1000e-02, 7.3600e-01, 9.9880e-01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954d3e3-163f-4c0c-ba10-498a29460d11",
   "metadata": {},
   "source": [
    "### Get a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b90bbfd-b330-4421-96f9-9984f60d65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5318, 0.4682]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 1# number of text corpuses being inputted\n",
    "predictions = model(tensor.reshape(-1,n_inputs,300), metrics.reshape(n_inputs,-1))\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e0e0ec-75d9-4ca7-9d10-e275c1e29aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability the text was Chat GPT created is  0.5318042635917664\n",
      "The probability the text was human created is  0.4681957960128784\n"
     ]
    }
   ],
   "source": [
    "pred_GPT = predictions[0][0].item()\n",
    "pred_human = predictions[0][1].item()\n",
    "\n",
    "print('The probability the text was Chat GPT created is ', pred_GPT)\n",
    "print('The probability the text was human created is ', pred_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18e1c4f-768a-4b54-8e2d-8eed381cd542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
