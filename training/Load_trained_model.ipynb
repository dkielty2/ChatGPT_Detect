{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3286b9c7-867a-47f5-8bc5-e2747e6d7ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.sys.path.append('./training')\n",
    "from pytorch_model import Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad7553c-ae55-4549-9e59-a8c198bbdefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "16  CPUs available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print(mp.cpu_count(),' CPUs available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb76a4-a999-4d77-85cf-6c90071d1287",
   "metadata": {},
   "source": [
    "## Saving/Loading a pytorch model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b02c27d4-5ed3-4273-ab3f-2ed7c49056f3",
   "metadata": {},
   "source": [
    "# define model\n",
    "model0 = Classifier(use_LSTM=True,N_metrics=5)\n",
    "#model0 = model0.to(device)# put it on gpu\n",
    "\n",
    "# save some test model weights\n",
    "model_weights_path = 'training/model_weights_rand.pt'\n",
    "torch.save(model0.state_dict(), model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27351d05-deec-4ca6-93aa-53955f727260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (text_read): LSTM(300, 128)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=133, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a new model with the exact same architecture\n",
    "model  = Classifier(use_LSTM=True,N_metrics=5)\n",
    "\n",
    "# load it\n",
    "seed = 6287 # for train test splitting\n",
    "epoch = 12\n",
    "batch_size = 10\n",
    "model_weights_path = 'training/model_weights_all_epoch%i_seed%s_batch%i.pt'%(epoch,seed,batch_size)\n",
    "model.load_state_dict(torch.load(model_weights_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aaa6ba-dad6-467a-8272-e64555597378",
   "metadata": {},
   "source": [
    "## Inputting text to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45cdf6b3-5fdf-421b-ae02-06c918026914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here's an essay I just copied from the web browser chat gpt\n",
    "input_text_test =\"\"\"Computers, the marvels of modern technology, have revolutionized the way we live, work, and interact with the world. These complex machines have evolved from room-sized calculators to sleek, multifunctional devices that permeate nearly every aspect of our daily lives.\n",
    "\n",
    "At their core, computers are electronic devices designed to process data and perform various tasks with remarkable speed and precision. They operate on the principles of binary code, using a series of ones and zeroes to represent and manipulate information. This binary system forms the basis of all computer functions, enabling the execution of intricate operations through logical sequences and algorithms.\n",
    "\n",
    "The history of computers spans several decades, marked by significant milestones and innovations. From the invention of the first mechanical computers by pioneers like Charles Babbage and Ada Lovelace to the development of transistors and integrated circuits, each advancement has contributed to the remarkable capabilities of modern computing devices.\n",
    "\n",
    "Today, computers come in various forms, ranging from powerful desktops and laptops to compact smartphones and tablets. They serve a multitude of purposes, facilitating communication, storing vast amounts of information, conducting research, and powering industries across the globe.\n",
    "\n",
    "The internet, a network of interconnected computers, has further expanded the capabilities of these machines. It serves as a gateway to an immeasurable wealth of information, enabling instant communication, online commerce, and global connectivity. The advent of cloud computing has revolutionized storage and accessibility, allowing users to access data and applications remotely with unparalleled convenience.\n",
    "\n",
    "Computers have also transformed industries, enhancing productivity and efficiency in fields such as healthcare, finance, education, and entertainment. They enable complex simulations, aid in scientific discoveries, automate tasks, and facilitate collaboration on a global scale.\n",
    "\n",
    "Moreover, the evolution of artificial intelligence (AI) has opened new frontiers in computing. AI-powered systems can learn, adapt, and make decisions, leading to advancements in areas like machine learning, natural language processing, and robotics.\n",
    "\n",
    "However, along with their myriad benefits, computers also pose challenges such as cybersecurity threats, ethical concerns regarding AI, and the digital divide that limits access to technology for some communities.\n",
    "\n",
    "In conclusion, computers stand as one of humanity's most transformative inventions, reshaping society and propelling progress in unprecedented ways. Their continued evolution and integration into various facets of our lives promise a future where innovation and technological advancement will continue to redefine what is possible. Embracing the potential of computers while addressing their challenges will be key to harnessing their power for the betterment of humanity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8047c30-394e-4d62-b3a8-296a4f0df8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a human generate text I put together\n",
    "input_text_test2 =\"\"\"Please help me! I don't know what I'm doing with my life! Who knows what the meaning of life is? Certainly not me.\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "940e0524-7e8d-47f5-bba4-c9ab3bedd4ac",
   "metadata": {},
   "source": [
    "print(input_text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99ffc6e-e993-49e0-9c8e-11f334fb1d2d",
   "metadata": {},
   "source": [
    "### We need to do a little preprocessing \n",
    "\n",
    "(it might take a bit for some things to load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74707e0d-f73c-4696-83cf-e2e986c1d850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1 µs, total: 7 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from preprocessing import preprocess,  metrics, w2v\n",
    "remap = {'a':'an', 'and':'also', 'of':'in', 'to':'at'}\n",
    "\n",
    "def process_for_model(text):\n",
    "    # extract metrics then do preprocessing\n",
    "    met = metrics(text)\n",
    "    \n",
    "    # do some processing \n",
    "    proc = preprocess(text)\n",
    "    processed_text_words = proc.split()# split by whitespace\n",
    "    essay_words = [remap[word] if word in remap.keys() else word for word in processed_text_words]\n",
    "    \n",
    "    # do word2vec\n",
    "    vecs = []\n",
    "    missing_words =[]\n",
    "    for word in essay_words:\n",
    "        try:\n",
    "            vec = w2v.get_vector(word)\n",
    "            vecs.append(vec)\n",
    "        except KeyError:\n",
    "            # this means that the word isn't in the w2v\n",
    "            missing_words.append(word)\n",
    "    vecs = np.array(vecs)\n",
    "    \n",
    "\n",
    "    #print all the words that are missing\n",
    "    unique_missing =  \" \".join(list(np.unique(np.array(missing_words))))\n",
    "    print('missing these words in model: ',unique_missing)\n",
    "    \n",
    "    torch_tensor = torch.from_numpy(vecs).reshape(-1,300)\n",
    "    torch_met = torch.from_numpy(met).float()\n",
    "    return torch_tensor, torch_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86f0e2bb-2e1c-4176-affe-16e3f152bddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing these words in model:  lovelass\n",
      "CPU times: user 162 ms, sys: 10.2 ms, total: 172 ms\n",
      "Wall time: 171 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tensor,metric = process_for_model(input_text_test)\n",
    "metric[0] = (np.log10(metric[0])-2.3)/2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f42b516f-94cc-4229-9f4e-ac446ef552f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3242, -0.2432,  0.1152,  ..., -0.0060, -0.0286, -0.0728],\n",
       "         [ 0.0801,  0.1050,  0.0498,  ...,  0.0037,  0.0476, -0.0688],\n",
       "         [ 0.2305,  0.2275, -0.1475,  ..., -0.2812,  0.1816,  0.1494],\n",
       "         ...,\n",
       "         [-0.2207,  0.0554,  0.1846,  ..., -0.1777,  0.0713, -0.1309],\n",
       "         [ 0.0703,  0.0869,  0.0879,  ..., -0.0476,  0.0145, -0.0625],\n",
       "         [ 0.1934,  0.2373,  0.4668,  ..., -0.1914,  0.1836,  0.1396]]),\n",
       " torch.Size([409, 300]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor, tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0c8a94f-f85a-4468-bb10-22520e99cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1660,  0.1190,  0.0060,  0.8750,  0.9917]), torch.Size([5]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric, metric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b954d3e3-163f-4c0c-ba10-498a29460d11",
   "metadata": {},
   "source": [
    "### Get a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b90bbfd-b330-4421-96f9-9984f60d65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 1.1807e-13]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_inputs = 1# number of text corpuses being inputted\n",
    "predictions = model(tensor.reshape(-1,n_inputs,300), metric.reshape(n_inputs,-1))\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98e0e0ec-75d9-4ca7-9d10-e275c1e29aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability the text was Chat GPT created is  1.0\n",
      "The probability the text was human created is  1.180696301361986e-13\n"
     ]
    }
   ],
   "source": [
    "pred_GPT = predictions[0][0].item()\n",
    "pred_human = predictions[0][1].item()\n",
    "\n",
    "print('The probability the text was Chat GPT created is ', pred_GPT)\n",
    "print('The probability the text was human created is ', pred_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af955dee-1ca4-4b6d-9cfd-964b8177a2bf",
   "metadata": {},
   "source": [
    "What about for my human essay?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c18e1c4f-768a-4b54-8e2d-8eed381cd542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing these words in model:  \n",
      "The probability the text was Chat GPT created is  0.00015260688087437302\n",
      "The probability the text was human created is  0.999847412109375\n"
     ]
    }
   ],
   "source": [
    "tensor, metric = process_for_model(input_text_test2)\n",
    "metric[0] = (np.log10(metric[0])-2.3)/2.3\n",
    "\n",
    "n_inputs = 1# number of text corpuses being inputted\n",
    "predictions = model(tensor.reshape(-1,n_inputs,300), metric.reshape(n_inputs,-1))\n",
    "pred_GPT = predictions[0][0].item()\n",
    "pred_human = predictions[0][1].item()\n",
    "\n",
    "print('The probability the text was Chat GPT created is ', pred_GPT)\n",
    "print('The probability the text was human created is ', pred_human)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144cd41-0e75-4684-a583-ffd52d90e7f9",
   "metadata": {},
   "source": [
    "## All together\n",
    "Trying to do a mix of text...(only the last line gpt generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73b375d5-6680-4e3a-a11f-b9c6afaf8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"I'm pretty sure I've seen a few that were, but they're fairly rare. Weight is a serious consideration, especially for bronze weapons, but that wasn't the real problem.\n",
    "\n",
    "Ironically, the wooden shaft is sturdier than an equivalently sized iron or bronze shaft would have been. A major problem for longswords in the early iron age was that they tended to bend from use. There's even a Roman account from combat with the Celts, where the Celts were using bronze longswords, and had to re-straighten their weapons on the battlefield because they were becoming bent and breaking.\n",
    "\n",
    "In fact the Romans specifically designed a non-reusable javelin (the pilum), which exploited this issue. The pilum had an abnormally long head (roughly 60cm) When the pilum struck its target, the head would bury into the target normally, but the weight of the grip would cause the iron shaft to deform, rendering the weapon unusable.\n",
    "\n",
    "The other side of this is that, as mentioned, wood is a lot tougher than people seem to think. I'm not sure where this idea that you could just casually chop through someone's spear with a sword came from, but as anyone who's ever tried to chop down a tree can tell you, yes in a fight between wood and metal, metal will win, but it takes a lot of effort to get there. Cutting through someone's spear with a single slice just isn't happening. That's not how wood works, and that's not how swords work. Though, attempting to do so is a good way to mangle your blade.\n",
    "\n",
    "Wooden spear shafts were reasonably durable, and easy to replace. Bronze or iron shafts were neither.\n",
    "\n",
    "Eventually, I think this was the 19th century, hollow steel shafts were used by cavalry. At that point in time you were looking at shafts that were significantly more durable than the wooden ones, and were cheap enough to produce that they could be easily fielded. Unfortunately, this only lasted a few decades until the proliferation of fully automatic firearms ended cavalry charges definitively. In another bit of irony, the technological advancement that allowed for effective metal spear shafts, is the same advancement that rendered them obsolete.\n",
    "\n",
    "I think there were some iron reinforced shafts used by some cavalry forces before that, but I can't remember (nor can I quickly find) who might have been using those.\n",
    "\n",
    "These days, hollow aluminum shafts are pretty common in javelins, and arrows, and they are generally superior to wooden shafts, however, the method to produce metallic aluminum wasn't discovered until the 19th century.\n",
    "\n",
    "So, the short answer, wooden shafts were better. They were sturdier and easier to replace.\n",
    "\n",
    "They encapsulate the essence of martial arts, cultural heritage, and recreational pursuits, embodying a timeless elegance that continues to intrigue and inspire enthusiasts around the world.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1054eb9-296e-42d4-9d25-2e617d42fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"\"\"So, uh, I know that this place is mostly for writing, but making your own TTRPG system kinda qualifies as writing, doesn't it?\n",
    "\n",
    "Either way - here's a fighting-related question that came up during my process making it. Is fear an important aspect of combat? Small-scale combat, to be specific, not the kind where you see a thousand of knights fight another thousand of knights. \n",
    "\n",
    "Would wounds (or even hits that are strong enough to be felt through armour) inflict noticeable stress to a well-trained soldier? Would it be bad enough to, potentially, make them panic, even if they aren't in any actual danger yet? Or would that mostly be a problem with inexperienced fighters, and training/combat experience could make someone relatively desensitized to that sort of thing? \n",
    "\n",
    "It's probably worded weirdly, I know, but, in general, what I'm trying to ask here is - should one consider stress/fear as a thing that might change the tides mid-combat, even if cowardice (or anything similar) isn't a major character trait for neither of the combatants?\n",
    "\n",
    "They encapsulate the essence of martial arts, cultural heritage, and recreational pursuits, embodying a timeless elegance that continues to intrigue and inspire enthusiasts around the world\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "170a938b-d1ae-4dde-aabf-0e889b33c935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing these words in model:  trutta\n",
      "tensor([-0.0163,  0.0810,  0.1860,  0.7330, -0.9769])\n",
      "The probability the text was Chat GPT created is  0.9999986886978149\n",
      "The probability the text was human created is  1.3369302678256645e-06\n"
     ]
    }
   ],
   "source": [
    "tensor, metric = process_for_model(input_text)\n",
    "metric[0] = (np.log10(metric[0])-2.3)/2.3\n",
    "print(metric)\n",
    "\n",
    "n_inputs = 1# number of text corpuses being inputted\n",
    "predictions = model(tensor.reshape(-1,n_inputs,300), metric.reshape(n_inputs,-1))\n",
    "pred_GPT = predictions[0][0].item()\n",
    "pred_human = predictions[0][1].item()\n",
    "\n",
    "print('The probability the text was Chat GPT created is ', pred_GPT)\n",
    "print('The probability the text was human created is ', pred_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a6c83-e91c-4ccc-954f-55760b6eedcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
